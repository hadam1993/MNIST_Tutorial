{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- Create Methods to load & visualize handwritten digits\n",
    "- Create the Neural Network\n",
    "- Create the Training & Validation Process\n",
    "- Create test process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Methods to load & visualize Handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2ab4025dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create the data loader that will load the images in from the directory num_training_class as a pytorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms documentation\n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision datasets documentation: https://pytorch.org/docs/stable/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./Train\"\n",
    "#Transform the images by converting to grayscale\n",
    "#loading them as a torch tensor, and normalizing\n",
    "#The images with a mean of 0.5 and std of 0.5\n",
    "transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "#Apply the transform to the dataset we are going to load in\n",
    "img_dataset = datasets.ImageFolder(img_path,transform)\n",
    "#Split data into training and validation sets\n",
    "train_set, val_set = torch.utils.data.random_split(img_dataset, [50000, 10000])\n",
    "#Create a data loader for the train set and validation sets. \n",
    "#They will give us batches of 64 images\n",
    "train_data_loader = DataLoader(dataset =train_set,batch_size=128,\n",
    "                               shuffle=True,num_workers=1)\n",
    "val_data_loader = DataLoader(dataset =val_set,batch_size=128,\n",
    "                             shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create a method to visualize the images that are collected from the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)),interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To iterate thru the images we can place the python native iter class over our dataloader and use the next method to load images and their associated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(val_data_loader)\n",
    "imgs, labels = data_iter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use the show method we created earlier to display all the images in the image batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(make_grid(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure the labels match with the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 3, 6, 9, 6, 6, 1, 7, 5, 0, 2, 3, 3, 0, 6, 7, 3, 1, 0, 7, 9, 4, 6,\n",
       "        2, 9, 9, 1, 4, 1, 7, 2, 4, 9, 5, 0, 5, 0, 8, 1, 1, 5, 1, 9, 0, 8, 6, 9,\n",
       "        7, 0, 9, 8, 1, 3, 3, 3, 9, 0, 3, 2, 5, 5, 8, 9, 3, 2, 6, 0, 1, 9, 4, 6,\n",
       "        5, 3, 4, 1, 2, 6, 5, 5, 4, 9, 0, 5, 1, 6, 5, 3, 0, 7, 0, 0, 7, 0, 6, 1,\n",
       "        5, 2, 6, 6, 7, 0, 1, 1, 5, 8, 5, 4, 5, 6, 2, 2, 9, 2, 0, 1, 6, 1, 2, 5,\n",
       "        1, 3, 0, 2, 6, 2, 8, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create a shallow network that has 784 input nodes, a hidden layer with 1000 nodes, and an output layer with 10 nodes representing the 10 possible digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shallow_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,1000)\n",
    "        self.out = nn.Linear(1000,10)\n",
    "    def forward(self,input):\n",
    "        x = F.sigmoid(self.fc1(input))\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medium_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Medium_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,1000)\n",
    "        self.fc2 = nn.Linear(1000,2000)\n",
    "        self.fc3 = nn.Linear(2000,1000)\n",
    "        self.out = nn.Linear(1000,10)\n",
    "    def forward(self,input):\n",
    "        x = F.relu(self.fc1(input))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "net = Shallow_Network()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Network onto the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim documentation https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an stochastic gradient descent optimizer or Adam Optimizer\n",
    "sgd  = optim.SGD(net.parameters(), lr=0.001)\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahonts/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "training loss:  0.45644423\n",
      "validation loss:  0.2978694\n",
      "accuracy:  0.9129746835443038\n",
      "epoch  1\n",
      "training loss:  0.23304144\n",
      "validation loss:  0.20522247\n",
      "accuracy:  0.9419501582278481\n",
      "epoch  2\n",
      "training loss:  0.16615483\n",
      "validation loss:  0.16155666\n",
      "accuracy:  0.9512460443037974\n",
      "epoch  3\n",
      "training loss:  0.124524616\n",
      "validation loss:  0.13199577\n",
      "accuracy:  0.9630142405063291\n",
      "epoch  4\n",
      "training loss:  0.097792834\n",
      "validation loss:  0.12019111\n",
      "accuracy:  0.964003164556962\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "average_losses = []\n",
    "average_val_losses = []\n",
    "acc = []\n",
    "min_validation = 100000.0\n",
    "min_val_epoch = 0\n",
    "for epoch in range(5):\n",
    "    data_iter = iter(train_data_loader)\n",
    "    cur_loss = []\n",
    "    while True:\n",
    "        try:\n",
    "            net.train()\n",
    "            #zero the gradient\n",
    "            adam.zero_grad()\n",
    "            #load the images and labels\n",
    "            imgs, labels = data_iter.next()\n",
    "            #Get output of network\n",
    "            probs = net(torch.flatten(imgs.to(device), start_dim=1))\n",
    "            #compute loss\n",
    "            loss = loss_func(probs,labels.to(device))\n",
    "            #compute the backward gradient and move network in that direction\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "            #gather loss\n",
    "            cur_loss.append(loss.detach().cpu().numpy())\n",
    "        except:\n",
    "            break\n",
    "    print(\"epoch \",epoch)\n",
    "    print(\"training loss: \", np.mean(cur_loss))\n",
    "    average_losses.append(np.mean(cur_loss))\n",
    "    \n",
    "    data_iter = iter(val_data_loader)\n",
    "    cur_val_loss = []\n",
    "    cur_acc = []\n",
    "    while True:\n",
    "        try:\n",
    "            net.eval()\n",
    "            imgs, labels = data_iter.next()\n",
    "            probs = net(torch.flatten(imgs.to(device), start_dim=1))\n",
    "            loss = loss_func(probs,labels.to(device))\n",
    "            cur_val_loss.append(loss.detach().cpu().numpy())\n",
    "            values, indices = torch.max(probs, 1)\n",
    "            accuracy = ((indices.to(device) - labels.to(device)) == 0).sum()\n",
    "            accuracy = accuracy.detach().cpu().numpy() / len(indices)\n",
    "            #print(accuracy)\n",
    "            cur_acc.append(accuracy)\n",
    "        except:\n",
    "            break\n",
    "    print(\"validation loss: \",np.mean(cur_val_loss))\n",
    "    average_losses.append(np.mean(cur_val_loss))\n",
    "    print(\"accuracy: \",np.mean(cur_acc))\n",
    "    average_losses.append(np.mean(cur_val_loss))\n",
    "    acc.append(np.mean(cur_acc))\n",
    "    if min_validation > np.mean(cur_val_loss):\n",
    "        min_validation = np.mean(cur_val_loss)\n",
    "        min_val_epoch = epoch\n",
    "        torch.save(net.state_dict(), './net_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./Test\"\n",
    "transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = datasets.ImageFolder(img_path,transform)\n",
    "test_data_loader = DataLoader(dataset =test_dataset,batch_size=1,shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.968\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(test_data_loader)\n",
    "test_acc = []\n",
    "while True:\n",
    "    try:\n",
    "        net.eval()\n",
    "        imgs, labels = data_iter.next()\n",
    "        probs = net(torch.flatten(imgs.to(device), start_dim=1))\n",
    "        values, indices = torch.max(probs, 1)\n",
    "        accuracy = ((indices.to(device) - labels.to(device)) == 0).sum()\n",
    "        accuracy = accuracy.detach().cpu().numpy() / len(indices)\n",
    "        #print(accuracy)\n",
    "        test_acc.append(accuracy)\n",
    "    except:\n",
    "        break\n",
    "print(\"accuracy: \",np.mean(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
